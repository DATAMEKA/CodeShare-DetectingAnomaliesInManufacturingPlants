{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133906ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T08:14:43.559526Z",
     "start_time": "2023-08-26T08:14:43.549536Z"
    }
   },
   "outputs": [],
   "source": [
    "import pyforest\n",
    "from glob import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, BatchNormalization, AveragePooling1D, LSTM, Bidirectional\n",
    "from keras.utils import np_utils, to_categorical\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ReduceLROnPlateau, EarlyStopping, CSVLogger, ModelCheckpoint\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, make_scorer, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "from imblearn.combine import SMOTETomek\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "import os\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "# librosa is a Python library for analyzing audio and music. It can be used to extract the data from the audio files we will see it later.\n",
    "import librosa\n",
    "import librosa.display\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# to play the audio files and show the audio files\n",
    "from IPython.display import Audio\n",
    "import IPython.display as ipd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f493e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-21T05:22:23.852918Z",
     "start_time": "2023-08-21T05:22:23.737984Z"
    }
   },
   "outputs": [],
   "source": [
    "label = pd.read_csv('label.csv')\n",
    "\n",
    "# Fungsi untuk menghasilkan jalur ke file berdasarkan file_id\n",
    "def get_sound_file_path(file_id):\n",
    "    folder_path = 'sounds'  # Ganti dengan jalur folder suara\n",
    "    file_extension = '.wav'  # Ganti dengan ekstensi file yang sesuai\n",
    "\n",
    "    file_name = str(file_id) + file_extension\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    return file_path\n",
    "\n",
    "# Menambahkan kolom baru ke DataFrame yang berisi jalur file suara\n",
    "label['file_path'] = label['file_id'].apply(get_sound_file_path)\n",
    "\n",
    "# Mengganti backslash (\\) dengan slash (/) pada jalur\n",
    "label['file_path'] = label['file_path'].str.replace('\\\\', '/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8530b9fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-21T00:50:38.042413Z",
     "start_time": "2023-08-21T00:50:37.965242Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_waveplot(data, sr, ):\n",
    "    plt.figure(figsize=(6, 3))\n",
    "    plt.title('Waveplot for audio with emotion', size=15)\n",
    "    librosa.display.waveshow(data, sr=sr)\n",
    "    plt.show()\n",
    "\n",
    "def create_spectrogram(data, sr):\n",
    "    # stft function converts the data into short term fourier transform\n",
    "    X = librosa.stft(data)\n",
    "    Xdb = librosa.amplitude_to_db(abs(X))\n",
    "    plt.figure(figsize=(6, 3))\n",
    "    plt.title('Spectrogram for audio with emotion', size=15)\n",
    "    librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz') \n",
    "    plt.ylabel(\"Frequency\")\n",
    "    #librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='log')\n",
    "    plt.colorbar()\n",
    "\n",
    "def create_spectrum(data, sr):\n",
    "    fft_normal = np.fft.fft(data) #fast Fourier transform\n",
    "    magnitude_normal = np.abs(fft_normal)\n",
    "    freq_normal = np.linspace(0,sr, len(magnitude_normal)) \n",
    "    half_freq = freq_normal[:int(len(freq_normal)/2)]\n",
    "    half_magnitude = magnitude_normal[:int(len(freq_normal)/2)]\n",
    "\n",
    "    plt.figure(figsize=(6,3))\n",
    "    plt.plot(half_freq,half_magnitude)\n",
    "    plt.title('Spectrum for audio with emotion', size=15)\n",
    "    plt.xlabel(\"Frequency\")\n",
    "    plt.ylabel(\"Magnitude\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abaaae61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-21T00:50:51.810403Z",
     "start_time": "2023-08-21T00:50:38.058020Z"
    }
   },
   "outputs": [],
   "source": [
    "path = np.array(label.file_path[label.split=='valid'])[10]\n",
    "data, sampling_rate = librosa.load(path)\n",
    "create_waveplot(data, sampling_rate)\n",
    "create_spectrogram(data, sampling_rate)\n",
    "create_spectrum(data, sampling_rate)\n",
    "Audio(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0600807",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-21T00:50:56.070594Z",
     "start_time": "2023-08-21T00:50:51.836654Z"
    }
   },
   "outputs": [],
   "source": [
    "path = np.array(label.file_path[label.split=='valid'])[358]\n",
    "data, sampling_rate = librosa.load(path)\n",
    "create_waveplot(data, sampling_rate)\n",
    "create_spectrogram(data, sampling_rate)\n",
    "create_spectrum(data, sampling_rate)\n",
    "Audio(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285741dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-21T05:22:23.883449Z",
     "start_time": "2023-08-21T05:22:23.859851Z"
    }
   },
   "outputs": [],
   "source": [
    "label_train = label[(label['split'] == 'train') | (label['split'] == 'valid')]\n",
    "label_test = label[label['split'] == 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759fe5da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-21T03:32:55.599116Z",
     "start_time": "2023-08-21T03:32:55.575565Z"
    }
   },
   "outputs": [],
   "source": [
    "label_train['abnormal'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa75406",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-21T00:50:56.684007Z",
     "start_time": "2023-08-21T00:50:56.133708Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.title('Count of Anomalies in Manufacturing Plants', size=16)\n",
    "sns.countplot(data = label_train, x = \"abnormal\")\n",
    "plt.ylabel('Count', size=12)\n",
    "plt.xlabel('Anomalies', size=12)\n",
    "sns.despine(top=True, right=True, left=False, bottom=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2215a3b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-21T05:23:27.757190Z",
     "start_time": "2023-08-21T05:23:27.709157Z"
    }
   },
   "outputs": [],
   "source": [
    "def noise(data):\n",
    "    noise_amp = 0.04*np.random.uniform()*np.amax(data)\n",
    "    data = data + noise_amp*np.random.normal(size=data.shape[0])\n",
    "    return data\n",
    "\n",
    "def stretch(data, rate=0.70):\n",
    "    return librosa.effects.time_stretch(data, rate)\n",
    "\n",
    "def shift(data):\n",
    "    shift_range = int(np.random.uniform(low=-5, high = 5)*1000)\n",
    "    return np.roll(data, shift_range)\n",
    "\n",
    "def pitch(data, sampling_rate, pitch_factor=1):\n",
    "    return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)\n",
    "\n",
    "def higher_speed(data, speed_factor = 1.25):\n",
    "    return librosa.effects.time_stretch(data, speed_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63857933",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-21T05:22:23.930161Z",
     "start_time": "2023-08-21T05:22:23.894133Z"
    }
   },
   "outputs": [],
   "source": [
    "# extract features with mfcc\n",
    "def extract_features(data):\n",
    "    \n",
    "    result = np.array([])\n",
    "    mfccs = librosa.feature.mfcc(y=data, sr=22050, n_mfcc=58) #\n",
    "    mfccs_processed = np.mean(mfccs.T,axis=0)\n",
    "    result = np.array(mfccs_processed)\n",
    "     \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84709278",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-21T05:22:23.976282Z",
     "start_time": "2023-08-21T05:22:23.944621Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_features(path):\n",
    "    data, sample_rate = librosa.load(path, duration=9.5, offset=0.5, res_type='kaiser_fast') \n",
    "    \n",
    "    augmentations = [\n",
    "        data,\n",
    "        noise(data),\n",
    "        shift(data)\n",
    "    ]\n",
    "    \n",
    "    results = [extract_features(aug) for aug in augmentations]\n",
    "    \n",
    "    result_array = np.array(results)\n",
    "    \n",
    "    return result_array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8edf086",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee47e4fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-21T05:24:52.272220Z",
     "start_time": "2023-08-21T05:23:31.108171Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fungsi untuk melakukan augmentasi pada DataFrame\n",
    "def augment_data(df, times):\n",
    "    augmented_dfs = []\n",
    "    \n",
    "    for _ in range(times):\n",
    "        augmented_df = label_test.copy()  # Meng-copy DataFrame awal\n",
    "        \n",
    "        # Lakukan augmentasi pada augmented_df dengan menggunakan get_features\n",
    "        augmented_df['features'] = augmented_df['file_path'].apply(get_features)\n",
    "        \n",
    "        augmented_dfs.append(augmented_df)\n",
    "    \n",
    "    return pd.concat(augmented_dfs, ignore_index=True)\n",
    "\n",
    "# Menentukan berapa kali augmentasi akan dilakukan\n",
    "augmentation_times = 1  # Ganti sesuai kebutuhan\n",
    "\n",
    "# Melakukan augmentasi pada DataFrame awal\n",
    "augmented_df_test = augment_data(label_test, augmentation_times)\n",
    "\n",
    "# Menampilkan jumlah baris DataFrame hasil\n",
    "print(len(augmented_df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64daa25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-21T05:40:23.118546Z",
     "start_time": "2023-08-21T05:40:23.058839Z"
    }
   },
   "outputs": [],
   "source": [
    "# Membuat kolom baru dari list yang ada\n",
    "num_elements = len(augmented_df_test['features'][0][0])  # Menghitung jumlah elemen dalam setiap list dalam list\n",
    "\n",
    "for i in range(num_elements):\n",
    "    col_name = f'col_{i+1}'\n",
    "    augmented_df_test[col_name] = augmented_df_test['features'].apply(lambda x: x[0][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6def1771",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-21T05:42:15.917118Z",
     "start_time": "2023-08-21T05:42:15.850414Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test = augmented_df_test.drop(['split', 'features', 'file_path'], axis = 1)\n",
    "df_test.to_csv('DfTestFix.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6915d0",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430064ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-21T05:54:59.889602Z",
     "start_time": "2023-08-21T05:43:31.031848Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fungsi untuk melakukan augmentasi pada DataFrame\n",
    "def augment_data(df, times):\n",
    "    augmented_dfs = []\n",
    "    \n",
    "    for _ in range(times):\n",
    "        augmented_df = label_train.copy()  # Meng-copy DataFrame awal\n",
    "        \n",
    "        # Lakukan augmentasi pada augmented_df dengan menggunakan get_features\n",
    "        augmented_df['features'] = augmented_df['file_path'].apply(get_features)\n",
    "        \n",
    "        augmented_dfs.append(augmented_df)\n",
    "    \n",
    "    return pd.concat(augmented_dfs, ignore_index=True)\n",
    "\n",
    "# Menentukan berapa kali augmentasi akan dilakukan\n",
    "augmentation_times = 1  # Ganti sesuai kebutuhan\n",
    "\n",
    "# Melakukan augmentasi pada DataFrame awal\n",
    "augmented_df= augment_data(label_train, augmentation_times)\n",
    "\n",
    "# Menampilkan jumlah baris DataFrame hasil\n",
    "print(len(augmented_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719d9400",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-21T05:55:49.907754Z",
     "start_time": "2023-08-21T05:55:49.668001Z"
    }
   },
   "outputs": [],
   "source": [
    "# Membuat kolom baru dari list yang ada\n",
    "num_elements = len(augmented_df['features'][0][0])  # Menghitung jumlah elemen dalam setiap list dalam list\n",
    "\n",
    "for i in range(num_elements):\n",
    "    col_name = f'col_{i+1}'\n",
    "    augmented_df[col_name] = augmented_df['features'].apply(lambda x: x[0][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca7d7ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-21T05:57:50.862021Z",
     "start_time": "2023-08-21T05:57:50.513618Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = augmented_df.drop(['split', 'features', 'file_path'], axis = 1)\n",
    "df_train['abnormal'] = df_train['abnormal'].map({False: 0, True: 1})\n",
    "df_train.to_csv('DfTrainFix.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628dba4f",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e6b3d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T07:56:32.827237Z",
     "start_time": "2023-08-26T07:56:32.740058Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read the CSV file\n",
    "train = pd.read_csv('DfTrainFix.csv')\n",
    "test = pd.read_csv('DfTestFix.csv')\n",
    "\n",
    "# Membagi variabel independen (X) dan dependen (Y)\n",
    "X = train.iloc[: ,2:]\n",
    "Y = train['abnormal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27e147f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T07:56:34.679904Z",
     "start_time": "2023-08-26T07:56:34.422463Z"
    }
   },
   "outputs": [],
   "source": [
    "# Menerapkan SMOTETomek\n",
    "smt = SMOTETomek(random_state = 0)\n",
    "X_resampled, y_resampled = smt.fit_resample(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe7bde1",
   "metadata": {},
   "source": [
    "## Machine Learning (XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c745a12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T07:37:02.992950Z",
     "start_time": "2023-08-26T07:37:02.965561Z"
    }
   },
   "outputs": [],
   "source": [
    "# Membagi data menjadi data latih 80% dan data test 20%\n",
    "x_train_ml, x_test_ml, y_train_ml, y_test_ml = train_test_split(X_resampled, y_resampled, random_state=42, test_size=0.20, shuffle=True)\n",
    "x_train_ml.shape, y_train_ml.shape, x_test_ml.shape, y_test_ml.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb24dd12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T07:38:11.879348Z",
     "start_time": "2023-08-26T07:38:11.852702Z"
    }
   },
   "outputs": [],
   "source": [
    "# Transformasi data menggunakan standart scale\n",
    "scaler_ml = StandardScaler()\n",
    "x_train_ml = scaler_ml.fit_transform(x_train_ml)\n",
    "x_test_ml = scaler_ml.transform(x_test_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94610c8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T07:38:17.856915Z",
     "start_time": "2023-08-26T07:38:17.845183Z"
    }
   },
   "outputs": [],
   "source": [
    "# parameter for tuning\n",
    "params={\n",
    "    \"learning_rate\":[0.05,0.10,0.15],\n",
    "    \"max_depth\":[3,5,7,9],\n",
    "    \"min_child_weight\":[5,7, 9],\n",
    "    \"gamma\":[0.5,0.1,0.3],\n",
    "    \"colsample_bytree\":[0.3,0.5,0.7],\n",
    "    \"random_state\":[1970, 2021, 2020]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca41ebb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T07:39:16.465657Z",
     "start_time": "2023-08-26T07:39:10.043713Z"
    }
   },
   "outputs": [],
   "source": [
    "# use xgboost hyperparameter tuning with method gpu\n",
    "classifier=xgb.XGBClassifier(tree_method='hist')\n",
    "\n",
    "# Definisikan skor AUC-ROC sebagai fungsi skor\n",
    "roc_auc_scorer = make_scorer(roc_auc_score, greater_is_better=True)\n",
    "\n",
    "# Buat objek RandomizedSearchCV dengan skor AUC-ROC dan cross-validation 5-fold\n",
    "random_search = RandomizedSearchCV(classifier, param_distributions=params, n_iter=5,\n",
    "                                   scoring=roc_auc_scorer, cv=5, verbose=3)\n",
    "\n",
    "# Lakukan tuning hyperparameter dengan AUC-ROC sebagai skor\n",
    "random_search.fit(x_train_ml, y_train_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403ecdc5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T07:39:30.514025Z",
     "start_time": "2023-08-26T07:39:30.490649Z"
    }
   },
   "outputs": [],
   "source": [
    "# Membuat prediksi pada data x_test_ml\n",
    "y_pred = random_search.predict(x_test_ml)\n",
    "\n",
    "# Menghitung metrik AUC-ROC\n",
    "auc_roc = roc_auc_score(y_test_ml, y_pred)\n",
    "\n",
    "print(\"AUC-ROC:\", auc_roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f987b0ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T07:39:35.219599Z",
     "start_time": "2023-08-26T07:39:35.190034Z"
    }
   },
   "outputs": [],
   "source": [
    "# predict to data test\n",
    "Y_pred = random_search.predict(x_test_ml)\n",
    "# confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test_ml, Y_pred)\n",
    "print('Akurasi test model:', accuracy_score(y_test_ml, Y_pred))\n",
    "print()\n",
    "print(\"Confusion Matrix\")\n",
    "print(cnf_matrix)\n",
    "print()\n",
    "print(classification_report(y_test_ml, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafc98b6",
   "metadata": {},
   "source": [
    "## Submission ML Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce35342c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T07:42:46.360151Z",
     "start_time": "2023-08-26T07:42:46.352815Z"
    }
   },
   "outputs": [],
   "source": [
    "XTest = test.iloc[: ,2:]\n",
    "XTest = scaler_ml.transform(XTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae76563a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T07:43:14.782862Z",
     "start_time": "2023-08-26T07:43:14.758757Z"
    }
   },
   "outputs": [],
   "source": [
    "YTest = random_search.predict(XTest)\n",
    "test['score'] = YTest\n",
    "sub = test[['file_id', 'score']]\n",
    "sub.to_csv('Sub3.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8065f19",
   "metadata": {},
   "source": [
    "## Deep Learning (LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85d414d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T08:20:09.806126Z",
     "start_time": "2023-08-26T08:20:09.782354Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model(in_shape):\n",
    "    weight_decay = 1e-4\n",
    "    L2 = tf.keras.regularizers.l2(weight_decay)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(128, dropout=0.05, recurrent_dropout=0.20, return_sequences=True), input_shape=(in_shape, 1)))\n",
    "    model.add(Conv1D(256, kernel_size=6, strides=1, padding='same', activation='relu', kernel_regularizer=L2))\n",
    "    model.add(AveragePooling1D(pool_size=4, strides=2, padding='same'))\n",
    "\n",
    "    model.add(Conv1D(128, kernel_size=6, strides=1, padding='same', activation='relu', kernel_regularizer=L2))\n",
    "    model.add(AveragePooling1D(pool_size=4, strides=2, padding='same'))\n",
    "\n",
    "    model.add(Conv1D(128, kernel_size=6, strides=1, padding='same', activation='relu', kernel_regularizer=L2))\n",
    "    model.add(AveragePooling1D(pool_size=4, strides=2, padding='same'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv1D(64, kernel_size=6, strides=1, padding='same', activation='relu', kernel_regularizer=L2))\n",
    "    model.add(MaxPooling1D(pool_size=4, strides=2, padding='same'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=32, activation='relu', kernel_regularizer=L2))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=0.01,\n",
    "        decay_steps=10000,\n",
    "        decay_rate=0.9\n",
    "    )\n",
    "\n",
    "    opt = RMSprop(lr=0.001, decay=1e-6)\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['AUC'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d540ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T08:20:21.868766Z",
     "start_time": "2023-08-26T08:20:21.859020Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reduce learning rate when a metric has stopped improving.\n",
    "reduce_learning_rate = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.5, patience=5, verbose=1, \n",
    "    mode='auto', min_delta=1e-10, cooldown=0, min_lr=0\n",
    ")\n",
    "\n",
    "# Stop training when a monitored metric has stopped improving.\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0, patience=12, verbose=1, mode='auto',\n",
    "    baseline=None, restore_best_weights=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236f7584",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T08:20:25.767019Z",
     "start_time": "2023-08-26T08:20:25.757495Z"
    }
   },
   "outputs": [],
   "source": [
    "# Callback that streams epoch results to a CSV file.\n",
    "csv_logger = tf.keras.callbacks.CSVLogger(\n",
    "    'da.epoch.results.csv', separator='|', append=False)\n",
    "\n",
    "# Callback to save the Keras model or model weights at some frequency.\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    \"da.partial.hdf5\", save_weights_only=True, mode='auto',\n",
    "    save_freq='epoch', verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97965bf2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T07:56:44.255171Z",
     "start_time": "2023-08-26T07:56:44.236365Z"
    }
   },
   "outputs": [],
   "source": [
    "# Membagi data menjadi data latih 80% dan data test 20%\n",
    "x_train_dl, x_test_dl, y_train_dl, y_test_dl = train_test_split(X_resampled, y_resampled, random_state=42, test_size=0.20, shuffle=True)\n",
    "x_train_dl.shape, y_train_dl.shape, x_test_dl.shape, y_test_dl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83c8187",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T07:56:45.250357Z",
     "start_time": "2023-08-26T07:56:45.212241Z"
    }
   },
   "outputs": [],
   "source": [
    "# Transformasi data menggunakan standart scale\n",
    "scaler_dl = StandardScaler()\n",
    "x_train_dl = scaler_dl.fit_transform(x_train_dl)\n",
    "x_test_dl = scaler_dl.transform(x_test_dl)\n",
    "\n",
    "x_train_dl = np.expand_dims(x_train_dl, axis=2)\n",
    "x_test_dl = np.expand_dims(x_test_dl, axis=2)\n",
    "x_train_dl.shape, y_train_dl.shape , x_test_dl.shape , y_test_dl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfdc655",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T08:20:30.594449Z",
     "start_time": "2023-08-26T08:20:30.324746Z"
    }
   },
   "outputs": [],
   "source": [
    "# summary model\n",
    "model = build_model(x_train_dl.shape[1])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515bae2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T08:29:12.142726Z",
     "start_time": "2023-08-26T08:20:34.845738Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 25\n",
    "batch_size = 32\n",
    "# fit the cnn model\n",
    "history = model.fit(\n",
    "    x_train_dl, y_train_dl,\n",
    "    steps_per_epoch=x_train_dl.shape[0]//batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(x_test_dl, y_test_dl),\n",
    "    callbacks=[csv_logger, reduce_learning_rate, early_stopping, model_checkpoint],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c41849",
   "metadata": {},
   "source": [
    "## Submission DL Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffc009a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T08:29:20.638674Z",
     "start_time": "2023-08-26T08:29:20.622094Z"
    }
   },
   "outputs": [],
   "source": [
    "XTest_dl = test.iloc[: ,2:]\n",
    "XTest_dl = scaler_dl.transform(XTest_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88a2e1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T08:29:22.270115Z",
     "start_time": "2023-08-26T08:29:21.542911Z"
    }
   },
   "outputs": [],
   "source": [
    "YTest_dl = model.predict(XTest_dl)\n",
    "test['score'] = YTest_dl\n",
    "sub_dl = test[['file_id', 'score']]\n",
    "sub_dl.to_csv('Sub2.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
